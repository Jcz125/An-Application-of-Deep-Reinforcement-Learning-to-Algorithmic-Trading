{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from agent import DRLAgent\n",
    "\n",
    "from meta.env_portfolio_allocation.env_portfolio import StockPortfolioEnv\n",
    "from meta.preprocessor.preprocessors import FeatureEngineer\n",
    "from meta.preprocessor.preprocessors import data_split\n",
    "from agent import *\n",
    "from meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "import meta.config as config\n",
    "from ppo import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (2012, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjcp</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-01-03</td>\n",
       "      <td>14.621429</td>\n",
       "      <td>14.732143</td>\n",
       "      <td>14.607143</td>\n",
       "      <td>14.686786</td>\n",
       "      <td>12.500191</td>\n",
       "      <td>302220800</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>14.642857</td>\n",
       "      <td>14.810000</td>\n",
       "      <td>14.617143</td>\n",
       "      <td>14.765714</td>\n",
       "      <td>12.567370</td>\n",
       "      <td>260022000</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>14.819643</td>\n",
       "      <td>14.948214</td>\n",
       "      <td>14.738214</td>\n",
       "      <td>14.929643</td>\n",
       "      <td>12.706893</td>\n",
       "      <td>271269600</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-01-06</td>\n",
       "      <td>14.991786</td>\n",
       "      <td>15.098214</td>\n",
       "      <td>14.972143</td>\n",
       "      <td>15.085714</td>\n",
       "      <td>12.839726</td>\n",
       "      <td>318292800</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>15.196429</td>\n",
       "      <td>15.276786</td>\n",
       "      <td>15.048214</td>\n",
       "      <td>15.061786</td>\n",
       "      <td>12.819365</td>\n",
       "      <td>394024400</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>2019-12-24</td>\n",
       "      <td>71.172501</td>\n",
       "      <td>71.222504</td>\n",
       "      <td>70.730003</td>\n",
       "      <td>71.067497</td>\n",
       "      <td>69.517082</td>\n",
       "      <td>48478800</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>2019-12-26</td>\n",
       "      <td>71.205002</td>\n",
       "      <td>72.495003</td>\n",
       "      <td>71.175003</td>\n",
       "      <td>72.477501</td>\n",
       "      <td>70.896339</td>\n",
       "      <td>93121200</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>2019-12-27</td>\n",
       "      <td>72.779999</td>\n",
       "      <td>73.492500</td>\n",
       "      <td>72.029999</td>\n",
       "      <td>72.449997</td>\n",
       "      <td>70.869415</td>\n",
       "      <td>146266000</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>72.364998</td>\n",
       "      <td>73.172501</td>\n",
       "      <td>71.305000</td>\n",
       "      <td>72.879997</td>\n",
       "      <td>71.290054</td>\n",
       "      <td>144114400</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>72.482498</td>\n",
       "      <td>73.419998</td>\n",
       "      <td>72.379997</td>\n",
       "      <td>73.412498</td>\n",
       "      <td>71.810928</td>\n",
       "      <td>100805600</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2012 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date       open       high        low      close      adjcp  \\\n",
       "0     2012-01-03  14.621429  14.732143  14.607143  14.686786  12.500191   \n",
       "1     2012-01-04  14.642857  14.810000  14.617143  14.765714  12.567370   \n",
       "2     2012-01-05  14.819643  14.948214  14.738214  14.929643  12.706893   \n",
       "3     2012-01-06  14.991786  15.098214  14.972143  15.085714  12.839726   \n",
       "4     2012-01-09  15.196429  15.276786  15.048214  15.061786  12.819365   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "2007  2019-12-24  71.172501  71.222504  70.730003  71.067497  69.517082   \n",
       "2008  2019-12-26  71.205002  72.495003  71.175003  72.477501  70.896339   \n",
       "2009  2019-12-27  72.779999  73.492500  72.029999  72.449997  70.869415   \n",
       "2010  2019-12-30  72.364998  73.172501  71.305000  72.879997  71.290054   \n",
       "2011  2019-12-31  72.482498  73.419998  72.379997  73.412498  71.810928   \n",
       "\n",
       "         volume   tic  day  \n",
       "0     302220800  AAPL    1  \n",
       "1     260022000  AAPL    2  \n",
       "2     271269600  AAPL    3  \n",
       "3     318292800  AAPL    4  \n",
       "4     394024400  AAPL    0  \n",
       "...         ...   ...  ...  \n",
       "2007   48478800  AAPL    1  \n",
       "2008   93121200  AAPL    3  \n",
       "2009  146266000  AAPL    4  \n",
       "2010  144114400  AAPL    0  \n",
       "2011  100805600  AAPL    1  \n",
       "\n",
       "[2012 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date       open      close       high        low      adjcp  \\\n",
      "0 2012-01-03  14.621429  14.686786  14.732143  14.607143  12.500191   \n",
      "\n",
      "      volume   tic  day  \n",
      "0  302220800  AAPL    1  \n",
      "Successfully added technical indicators\n",
      "Empty DataFrame\n",
      "Columns: [date, open, close, high, low, adjcp, volume, tic, day, macd, boll_ub, boll_lb, rsi_30, cci_30, dx_30, close_30_sma, close_60_sma, cov_list, return_list]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\amine\\AppData\\Local\\Temp\\ipykernel_17884\\383091794.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32md:\\Software\\Anaconda\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32md:\\Software\\Anaconda\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32md:\\Software\\Anaconda\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:2263\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:2273\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 63\u001b[0m\n\u001b[0;32m     51\u001b[0m state_space \u001b[39m=\u001b[39m stock_dimension\n\u001b[0;32m     52\u001b[0m env_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m     53\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mhmax\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m100\u001b[39m, \n\u001b[0;32m     54\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39minitial_amount\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m1000000\u001b[39m, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mreward_scaling\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m1e-4\u001b[39m\n\u001b[0;32m     61\u001b[0m }\n\u001b[1;32m---> 63\u001b[0m ppo_model, ppo_return \u001b[39m=\u001b[39m run_ppo_model(df_, \u001b[39m\"\u001b[39;49m\u001b[39mdate\u001b[39;49m\u001b[39m\"\u001b[39;49m, pd\u001b[39m.\u001b[39;49mto_datetime(trade_date[idx\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]), env_kwargs, \n\u001b[0;32m     64\u001b[0m                                       start_date, end_date, split_date)\n\u001b[0;32m     65\u001b[0m                                       \u001b[39m# testing_window, max_rolling_window)\u001b[39;00m\n\u001b[0;32m     67\u001b[0m trade \u001b[39m=\u001b[39m data_split(df_, pd\u001b[39m.\u001b[39mto_datetime(trade_date[idx\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]), pd\u001b[39m.\u001b[39mto_datetime(trade_date[idx]))\n",
      "File \u001b[1;32md:\\COURS\\UdS\\An-Application-of-Deep-Reinforcement-Learning-to-Algorithmic-Trading\\Alpha\\ppo.py:50\u001b[0m, in \u001b[0;36mrun_ppo_model\u001b[1;34m(df, date_column, trade_date, env_kwargs, start_date, end_date, split_date, testing_window, max_rolling_window)\u001b[0m\n\u001b[0;32m     47\u001b[0m agent = DRLAgent(env = env_train)\n\u001b[0;32m     48\u001b[0m ppo_model = train_ppo(agent)\n\u001b[1;32m---> 50\u001b[0m # Test\n\u001b[0;32m     51\u001b[0m e_trade_gym = StockPortfolioEnv(df=X_test, **env_kwargs)    \n\u001b[0;32m     52\u001b[0m df_daily_return, df_actions = DRLAgent.DRL_prediction(model=ppo_model, environment=e_trade_gym)\n",
      "File \u001b[1;32md:\\COURS\\UdS\\An-Application-of-Deep-Reinforcement-Learning-to-Algorithmic-Trading\\Alpha\\meta\\env_portfolio_allocation\\env_portfolio.py:106\u001b[0m, in \u001b[0;36mStockPortfolioEnv.__init__\u001b[1;34m(self, df, stock_dim, hmax, initial_amount, transaction_cost_pct, reward_scaling, state_space, action_space, tech_indicator_list, turbulence_threshold, lookback, day)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobservation_space \u001b[39m=\u001b[39m spaces\u001b[39m.\u001b[39mBox(\n\u001b[0;32m    100\u001b[0m     low\u001b[39m=\u001b[39m\u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39minf,\n\u001b[0;32m    101\u001b[0m     high\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39minf,\n\u001b[0;32m    102\u001b[0m     shape\u001b[39m=\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate_space \u001b[39m+\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtech_indicator_list), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate_space),\n\u001b[0;32m    103\u001b[0m )\n\u001b[0;32m    105\u001b[0m \u001b[39m# load data from a pandas dataframe\u001b[39;00m\n\u001b[1;32m--> 106\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdf\u001b[39m.\u001b[39;49mloc[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mday, :]\n\u001b[0;32m    107\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcovs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[\u001b[39m\"\u001b[39m\u001b[39mcov_list\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mvalues[\u001b[39m0\u001b[39m]\n\u001b[0;32m    108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mappend(\n\u001b[0;32m    109\u001b[0m     np\u001b[39m.\u001b[39marray(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcovs),\n\u001b[0;32m    110\u001b[0m     [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[tech]\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mtolist() \u001b[39mfor\u001b[39;00m tech \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtech_indicator_list],\n\u001b[0;32m    111\u001b[0m     axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,\n\u001b[0;32m    112\u001b[0m )\n",
      "File \u001b[1;32md:\\Software\\Anaconda\\lib\\site-packages\\pandas\\core\\indexing.py:1067\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1065\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m   1066\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_value(\u001b[39m*\u001b[39mkey, takeable\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_takeable)\n\u001b[1;32m-> 1067\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple(key)\n\u001b[0;32m   1068\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1069\u001b[0m     \u001b[39m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[0;32m   1070\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32md:\\Software\\Anaconda\\lib\\site-packages\\pandas\\core\\indexing.py:1247\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1245\u001b[0m \u001b[39mwith\u001b[39;00m suppress(IndexingError):\n\u001b[0;32m   1246\u001b[0m     tup \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expand_ellipsis(tup)\n\u001b[1;32m-> 1247\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_lowerdim(tup)\n\u001b[0;32m   1249\u001b[0m \u001b[39m# no multi-index, so validate all of the indexers\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m tup \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_tuple_indexer(tup)\n",
      "File \u001b[1;32md:\\Software\\Anaconda\\lib\\site-packages\\pandas\\core\\indexing.py:967\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_lowerdim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    963\u001b[0m \u001b[39mfor\u001b[39;00m i, key \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tup):\n\u001b[0;32m    964\u001b[0m     \u001b[39mif\u001b[39;00m is_label_like(key):\n\u001b[0;32m    965\u001b[0m         \u001b[39m# We don't need to check for tuples here because those are\u001b[39;00m\n\u001b[0;32m    966\u001b[0m         \u001b[39m#  caught by the _is_nested_tuple_indexer check above.\u001b[39;00m\n\u001b[1;32m--> 967\u001b[0m         section \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_axis(key, axis\u001b[39m=\u001b[39;49mi)\n\u001b[0;32m    969\u001b[0m         \u001b[39m# We should never have a scalar section here, because\u001b[39;00m\n\u001b[0;32m    970\u001b[0m         \u001b[39m#  _getitem_lowerdim is only called after a check for\u001b[39;00m\n\u001b[0;32m    971\u001b[0m         \u001b[39m#  is_scalar_access, which that would be.\u001b[39;00m\n\u001b[0;32m    972\u001b[0m         \u001b[39mif\u001b[39;00m section\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim:\n\u001b[0;32m    973\u001b[0m             \u001b[39m# we're in the middle of slicing through a MultiIndex\u001b[39;00m\n\u001b[0;32m    974\u001b[0m             \u001b[39m# revise the key wrt to `section` by inserting an _NS\u001b[39;00m\n",
      "File \u001b[1;32md:\\Software\\Anaconda\\lib\\site-packages\\pandas\\core\\indexing.py:1312\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1310\u001b[0m \u001b[39m# fall thru to straight lookup\u001b[39;00m\n\u001b[0;32m   1311\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m-> 1312\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_label(key, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[1;32md:\\Software\\Anaconda\\lib\\site-packages\\pandas\\core\\indexing.py:1260\u001b[0m, in \u001b[0;36m_LocIndexer._get_label\u001b[1;34m(self, label, axis)\u001b[0m\n\u001b[0;32m   1258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_label\u001b[39m(\u001b[39mself\u001b[39m, label, axis: \u001b[39mint\u001b[39m):\n\u001b[0;32m   1259\u001b[0m     \u001b[39m# GH#5567 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[1;32m-> 1260\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49mxs(label, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[1;32md:\\Software\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.py:4056\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[1;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[0;32m   4054\u001b[0m             new_index \u001b[39m=\u001b[39m index[loc]\n\u001b[0;32m   4055\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 4056\u001b[0m     loc \u001b[39m=\u001b[39m index\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   4058\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(loc, np\u001b[39m.\u001b[39mndarray):\n\u001b[0;32m   4059\u001b[0m         \u001b[39mif\u001b[39;00m loc\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mbool_:\n",
      "File \u001b[1;32md:\\Software\\Anaconda\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "startingDate = '2012-1-1'\n",
    "endingDate = '2020-1-1'\n",
    "splitingDate = '2018-1-1'\n",
    "\n",
    "df_price = YahooDownloader(startingDate, endingDate, ['AAPL']).fetch_data()\n",
    "display(df_price)\n",
    "df = df_price[['date', 'open', 'close', 'high', 'low', 'adjcp', 'volume', 'tic']]\n",
    "df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')\n",
    "df['day'] = [x.weekday() for x in df['date']]\n",
    "df.drop_duplicates(['tic', 'date'], inplace=True)\n",
    "\n",
    "trade_date = df['date'].to_numpy()\n",
    "\n",
    "\n",
    "df_dict = {'trade_date':[], 'tic':[], 'weights':[]}\n",
    "testing_window = pd.Timedelta(np.timedelta64(2,'Y'))\n",
    "max_rolling_window = pd.Timedelta(np.timedelta64(10, 'Y'))\n",
    "\n",
    "start_date = np.datetime64('2012-01-01')\n",
    "end_date = np.datetime64('2020-01-01')\n",
    "split_date = np.datetime64('2018-01-01')\n",
    "\n",
    "for idx in range(1, len(trade_date)):\n",
    "    p1_stock = ['AAPL']\n",
    "    earliest_date = pd.to_datetime(trade_date[idx-1]) # pd.to_datetime(trade_date[idx-1]) - max_rolling_window\n",
    "\n",
    "    df_ = df[df['tic'].isin(p1_stock) & (df['date'] >= earliest_date) & (df['date'] < trade_date[idx])]\n",
    "    print(df_)\n",
    "    fe = FeatureEngineer(use_technical_indicator=True, use_turbulence=False, user_defined_feature=False)\n",
    "    df_ = fe.preprocess_data(df_)\n",
    "    df_ = df_.sort_values(['date', 'tic'], ignore_index=True)\n",
    "    df_.index = df_.date.factorize()[0]\n",
    "    cov_list = []\n",
    "    return_list = []\n",
    "\n",
    "    # look back is one year\n",
    "    lookback = 252\n",
    "    for i in range(lookback, len(df_.index.unique())):\n",
    "        data_lookback = df_.loc[i-lookback:i,:]\n",
    "        price_lookback = data_lookback.pivot_table(index='date', columns='tic', values='close')\n",
    "        return_lookback = price_lookback.pct_change().dropna()\n",
    "        return_list.append(return_lookback)\n",
    "        covs = return_lookback.cov().values\n",
    "        cov_list.append(covs)\n",
    "\n",
    "    df_cov = pd.DataFrame({'date':df_.date.unique()[lookback:], 'cov_list':cov_list, 'return_list':return_list})\n",
    "    df_ = df_.merge(df_cov, on='date')\n",
    "    df_ = df_.sort_values(['date','tic']).reset_index(drop=True)\n",
    "\n",
    "    stock_dimension = len(df_.tic.unique())\n",
    "    state_space = stock_dimension\n",
    "    env_kwargs = {\n",
    "        \"hmax\": 100, \n",
    "        \"initial_amount\": 1000000, \n",
    "        \"transaction_cost_pct\": 0.001, \n",
    "        \"state_space\": state_space, \n",
    "        \"stock_dim\": stock_dimension, \n",
    "        \"tech_indicator_list\": config.INDICATORS, \n",
    "        \"action_space\": stock_dimension, \n",
    "        \"reward_scaling\": 1e-4\n",
    "    }\n",
    "\n",
    "    ppo_model, ppo_return = run_ppo_model(df_, \"date\", pd.to_datetime(trade_date[idx-1]), env_kwargs, \n",
    "                                          start_date, end_date, split_date)\n",
    "                                          # testing_window, max_rolling_window)\n",
    "    \n",
    "    trade = data_split(df_, pd.to_datetime(trade_date[idx-1]), pd.to_datetime(trade_date[idx]))\n",
    "    e_trade_gym = StockPortfolioEnv(df = trade, **env_kwargs)\n",
    "    df_daily_return, df_actions = DRLAgent.DRL_prediction(model=ppo_model, environment=e_trade_gym)\n",
    "\n",
    "    for i in range(len(df_actions)):\n",
    "        for j in df_actions.columns:\n",
    "            df_dict['trade_date'].append(df_actions.index[i])\n",
    "            df_dict['tic'].append(j)\n",
    "            df_dict['weights'].append(df_actions.loc[df_actions.index[i], j])\n",
    "\n",
    "\n",
    "df_rl = pd.DataFrame(df_dict)\n",
    "df_rl.to_csv(\"drl_weight.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
