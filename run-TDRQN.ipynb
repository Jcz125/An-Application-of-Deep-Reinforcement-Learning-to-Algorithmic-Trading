{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tradingSimulator import TradingSimulator\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (20.0, 10.0)\n",
    "matplotlib.rcParams['interactive'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization of the required variables\n",
    "stocks = [\"AAPL\", \"TSLA\"]\n",
    "money = 100000\n",
    "\n",
    "# Plotting settings\n",
    "trainShowPerformance = True \n",
    "trainPlot = True\n",
    "plotTrainEnv = True\n",
    "interactiveTest = False\n",
    "testShowPerformance = True\n",
    "testPlotQValues = True\n",
    "testOnLiveData = False\n",
    "trainTestRendering = False\n",
    "saveStrategy = True\n",
    "\n",
    "# Init simulator instance\n",
    "simulator = TradingSimulator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================== TRAINING PHASE ===================================\n",
      "[[12.4829317582426, 12.5500165506598, 12.6893465041416, 12.8219983334914, 12.8016604099984, 12.8474966256319, 12.8265515999451, 12.7913396727035, 12.7433785993916, 12.8918150857808, 13.0256811195182, 12.9843981703384, 12.7582526031402, 12.9740470779338, 12.7615916652063, 13.5584132945958, 13.496792421923, 13.5772334626043, 13.7511682411339, 13.8565004717617, 13.8476974899513, 13.8152175225819, 13.953636822773, 14.0838602433476, 14.231386076446, 14.4696736875206, 14.9702294463257, 14.9778182237484, 15.2564781307121, 15.4647141831926], [409.0, 409.28, 412.67, 419.22, 421.35, 421.5, 419.31, 418.75, 418.66, 422.96, 426.3, 426.51, 419.75, 422.3, 419.55, 443.73, 443.14, 443.77, 445.39, 453.07, 455.55, 453.98, 455.56, 458.201, 464.581, 469.7, 480.56, 488.55, 497.09, 502.0], [412.5, 414.68, 418.55, 422.75, 427.75, 426.0, 422.85, 422.9, 420.45, 425.99, 429.47, 431.369, 427.5, 428.45, 425.1001, 454.45, 448.79, 448.48, 453.9, 458.24, 458.99, 457.17, 460.0, 464.98, 469.75, 476.79, 496.75, 497.62, 503.83, 509.56], [10793600.0, 9286500.0, 9688200.0, 11367600.0, 14072300.0, 9221300.0, 7681600.0, 7592400.0, 8072200.0, 8674900.0, 9885400.0, 9347800.0, 14784800.0, 10930800.0, 19558500.0, 34225500.0, 11570900.0, 10703900.0, 13547900.0, 13988700.0, 9644500.0, 6671300.0, 10235700.0, 8907600.0, 11293700.0, 14567500.0, 31579100.0, 22546500.0, 18472000.0, 16442800.0]]\n",
      "[[40.8347107944992, 40.8275992112887, 41.0172414302345, 41.4842353943885, 41.3301510914951, 41.3254100360214, 41.3159279250741, 41.5506101710195, 41.9796756913843, 41.7663281950703, 42.4561517664856, 42.4940802102748, 42.304437991329, 41.9583409417529, 41.9678230527002, 41.2993342309164, 40.5621001047647, 40.6569212142375, 39.8153838676657, 39.5807016217203, 39.6897458976141, 39.7727143684029, 38.0469701759963, 37.0963885535306, 38.6467136934123, 37.8193995132614, 36.7787378367964, 37.2267675790558, 38.7262154132611, 39.1141677894127], [169.26, 171.96, 172.08, 173.05, 173.93, 173.41, 173.0, 174.49, 175.65, 176.14, 175.07, 178.25, 177.41, 176.6, 176.82, 173.2, 170.53, 170.06, 167.07, 164.7, 166.5, 166.76, 160.1, 156.0, 154.0, 159.07, 155.03, 150.24, 157.51, 161.65], [172.3, 174.55, 173.47, 175.37, 175.61, 175.06, 174.3, 175.49, 177.36, 179.39, 179.25, 180.1, 179.58, 177.78, 179.44, 177.3, 174.95, 172.0, 170.16, 167.37, 168.44, 168.62, 166.8, 163.88, 163.72, 163.4, 161.0, 157.89, 163.89, 164.75], [25048048.0, 28819653.0, 22211345.0, 23016177.0, 20134092.0, 21262614.0, 23589129.0, 17523256.0, 25039531.0, 29159005.0, 32752734.0, 30234512.0, 30827809.0, 26023683.0, 31702531.0, 50562257.0, 39661804.0, 37121805.0, 48434424.0, 45137026.0, 30984099.0, 38099665.0, 85436075.0, 66090446.0, 66625484.0, 50852130.0, 49594129.0, 66723743.0, 60560145.0, 32104756.0]]\n",
      "Training progression (hardware selected => cuda:0):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "must be real number, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m strategy \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mTDRQN\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m stock \u001b[39min\u001b[39;00m stocks:\n\u001b[0;32m      4\u001b[0m     \u001b[39m# Training and testing of the trading strategy specified for the stock (market) specified\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     tradingStrategy, trainingEnv, testingEnv \u001b[39m=\u001b[39m simulator\u001b[39m.\u001b[39;49msimulateNewStrategy(\n\u001b[0;32m      6\u001b[0m         strategy, \n\u001b[0;32m      7\u001b[0m         stock,\n\u001b[0;32m      8\u001b[0m         money\u001b[39m=\u001b[39;49mmoney,\n\u001b[0;32m      9\u001b[0m         interactiveTrain\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, \n\u001b[0;32m     10\u001b[0m         trainShowPerformance\u001b[39m=\u001b[39;49mtrainShowPerformance, \n\u001b[0;32m     11\u001b[0m         trainPlot\u001b[39m=\u001b[39;49mtrainPlot, \n\u001b[0;32m     12\u001b[0m         plotTrainEnv\u001b[39m=\u001b[39;49mplotTrainEnv,\n\u001b[0;32m     13\u001b[0m         interactiveTest\u001b[39m=\u001b[39;49minteractiveTest,\n\u001b[0;32m     14\u001b[0m         testShowPerformance\u001b[39m=\u001b[39;49mtestShowPerformance,\n\u001b[0;32m     15\u001b[0m         testPlotQValues\u001b[39m=\u001b[39;49mtestPlotQValues,\n\u001b[0;32m     16\u001b[0m         testOnLiveData\u001b[39m=\u001b[39;49mtestOnLiveData,\n\u001b[0;32m     17\u001b[0m         trainTestRendering\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     18\u001b[0m         saveStrategy\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m     19\u001b[0m     )\n",
      "File \u001b[1;32md:\\COURS\\UdS\\An-Application-of-Deep-Reinforcement-Learning-to-Algorithmic-Trading\\tradingSimulator.py:176\u001b[0m, in \u001b[0;36mTradingSimulator.simulateNewStrategy\u001b[1;34m(self, strategyName, stockName, money, batch_mode, batch_size, interactiveTrain, trainShowPerformance, trainPlot, plotTrainEnv, interactiveTest, testShowPerformance, testOnLiveData, testPlotQValues, trainTestRendering, saveStrategy)\u001b[0m\n\u001b[0;32m    166\u001b[0m     trainingEnv \u001b[39m=\u001b[39m tradingStrategy\u001b[39m.\u001b[39mtrainingBatch(trainingEnv, \n\u001b[0;32m    167\u001b[0m                                                 \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontext,\n\u001b[0;32m    168\u001b[0m                                                 trainingParameters\u001b[39m=\u001b[39mtrainingParameters,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    173\u001b[0m                                                 showPerformance\u001b[39m=\u001b[39mtrainShowPerformance,\n\u001b[0;32m    174\u001b[0m                                                 interactiveTradingGraph\u001b[39m=\u001b[39minteractiveTrain)\n\u001b[0;32m    175\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 176\u001b[0m     trainingEnv \u001b[39m=\u001b[39m tradingStrategy\u001b[39m.\u001b[39;49mtraining(trainingEnv, \n\u001b[0;32m    177\u001b[0m                                            \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcontext,\n\u001b[0;32m    178\u001b[0m                                            trainingParameters\u001b[39m=\u001b[39;49mtrainingParameters,\n\u001b[0;32m    179\u001b[0m                                            verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, \n\u001b[0;32m    180\u001b[0m                                            rendering\u001b[39m=\u001b[39;49mDisplayOption(\u001b[39mFalse\u001b[39;49;00m, plotTrainEnv, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m    181\u001b[0m                                            plotTraining\u001b[39m=\u001b[39;49mDisplayOption(\u001b[39mFalse\u001b[39;49;00m, trainPlot, \u001b[39mFalse\u001b[39;49;00m), \n\u001b[0;32m    182\u001b[0m                                            showPerformance\u001b[39m=\u001b[39;49mtrainShowPerformance,\n\u001b[0;32m    183\u001b[0m                                            interactiveTradingGraph\u001b[39m=\u001b[39;49minteractiveTrain)\n\u001b[0;32m    184\u001b[0m \u001b[39m# 3. TESTING PHASE\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[39m# Initialize the trading environment associated with the testing phase\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m=================================== TESTING PHASE ===================================\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\COURS\\UdS\\An-Application-of-Deep-Reinforcement-Learning-to-Algorithmic-Trading\\DRL\\TDRQN.py:357\u001b[0m, in \u001b[0;36mTDRQN.training\u001b[1;34m(self, trainingEnv, context, trainingParameters, verbose, rendering, plotTraining, showPerformance, interactiveTradingGraph)\u001b[0m\n\u001b[0;32m    355\u001b[0m stepsCounter \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    356\u001b[0m \u001b[39mif\u001b[39;00m stepsCounter \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlearningUpdatePeriod:\n\u001b[1;32m--> 357\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlearning(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatchSize)\n\u001b[0;32m    358\u001b[0m     stepsCounter \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    359\u001b[0m \u001b[39m# Update the RL state\u001b[39;00m\n",
      "File \u001b[1;32md:\\COURS\\UdS\\An-Application-of-Deep-Reinforcement-Learning-to-Algorithmic-Trading\\DRL\\TDRQN.py:237\u001b[0m, in \u001b[0;36mTDRQN.learning\u001b[1;34m(self, batchSize)\u001b[0m\n\u001b[0;32m    235\u001b[0m state, action, reward, nextState, done \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplayMemory\u001b[39m.\u001b[39msample(batchSize)\n\u001b[0;32m    236\u001b[0m \u001b[39m# Initialization of Pytorch tensors for the RL experience elements\u001b[39;00m\n\u001b[1;32m--> 237\u001b[0m state \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mtensor(state, dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mfloat, device\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice)\n\u001b[0;32m    238\u001b[0m action \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(action, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m    239\u001b[0m reward \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(reward, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "\u001b[1;31mTypeError\u001b[0m: must be real number, not NoneType"
     ]
    }
   ],
   "source": [
    "strategy = \"TDRQN\"\n",
    "\n",
    "for stock in stocks:\n",
    "    # Training and testing of the trading strategy specified for the stock (market) specified\n",
    "    tradingStrategy, trainingEnv, testingEnv = simulator.simulateNewStrategy(\n",
    "        strategy, \n",
    "        stock,\n",
    "        money=money,\n",
    "        interactiveTrain=False, \n",
    "        trainShowPerformance=trainShowPerformance, \n",
    "        trainPlot=trainPlot, \n",
    "        plotTrainEnv=plotTrainEnv,\n",
    "        interactiveTest=interactiveTest,\n",
    "        testShowPerformance=testShowPerformance,\n",
    "        testPlotQValues=testPlotQValues,\n",
    "        testOnLiveData=testOnLiveData,\n",
    "        trainTestRendering=False,\n",
    "        saveStrategy=True\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
